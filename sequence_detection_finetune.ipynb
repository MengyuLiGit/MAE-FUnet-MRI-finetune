{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from utils.help_func import create_path, print_var_detail\n",
    "# Ordered label list used in your training\n",
    "detect_sequence = ['T1_T1flair', 'T2', 'T2flair_flair', 'PD', 'T2star_hemo', 'T2star_swi', 'DTI_DWI']\n",
    "\n",
    "class MRISequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, dtype=torch.float32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Path to the root directory (e.g. ./finetune_data/sequence_detection/train)\n",
    "            transform: Optional transform (not needed if .npy files are already [3, 224, 224] and normalized)\n",
    "            dtype: Tensor type (e.g., torch.float32 or torch.float16)\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.label_map = {name: i for i, name in enumerate(detect_sequence)}\n",
    "        self.transform = transform\n",
    "        self.dtype = dtype\n",
    "\n",
    "        for label_name in detect_sequence:\n",
    "            class_dir = os.path.join(root_dir, label_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            for fname in os.listdir(class_dir):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.samples.append((os.path.join(class_dir, fname), self.label_map[label_name]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_idx = self.samples[idx]\n",
    "\n",
    "        # Load image (3, 224, 224), normalized [0,1]\n",
    "        img = np.load(img_path).astype(np.float32)\n",
    "        img_tensor = torch.tensor(img, dtype=self.dtype)\n",
    "\n",
    "        # One-hot encode label\n",
    "        label_tensor = torch.zeros(len(detect_sequence), dtype=torch.float32)\n",
    "        label_tensor[label_idx] = 1.0\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        return img_tensor, label_tensor\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloaders(train_root, test_root, batch_size=64, num_workers=4, dtype=torch.float32):\n",
    "    train_dataset = MRISequenceDataset(train_root, dtype=dtype)\n",
    "    test_dataset = MRISequenceDataset(test_root, dtype=dtype)\n",
    "\n",
    "    loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                             num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return loader_train, loader_test\n"
   ],
   "id": "e7c8eca7b2fd234c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_root = './finetune_data/sequence_detection/train'\n",
    "test_root = './finetune_data/sequence_detection/test'\n",
    "batch_size = 256\n",
    "dataloader_train, dataloader_val = get_dataloaders(train_root, test_root, batch_size=batch_size, num_workers=0, dtype=torch.float16)\n"
   ],
   "id": "5410d52ba1ed6efe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "images, labels = next(iter(dataloader_train))\n",
    "image_tensor = images\n",
    "one_hot_tensor = labels\n",
    "label_indices = torch.argmax(one_hot_tensor, dim=1)"
   ],
   "id": "f2b5cd23da74d006",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_tensor[0].to(dtype=torch.float32).permute(1, 2, 0), cmap='gray')\n",
    "plt.show()"
   ],
   "id": "6d5cd7d8f72402ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sequence_detection.models_mae_finetune import MaskedAutoencoderViTClassify\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "model = MaskedAutoencoderViTClassify(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes=len(detect_sequence) + 1, mode='cls')\n",
    "\n",
    "pretrain_path = './saved_models/mae_vit_base_patch16_pretrain_test0.75_E30/model_E30.pt'\n",
    "\n",
    "missing, unexpected = model.load_state_dict(torch.load(pretrain_path)['model_state_dict'], strict=False)  # strict=False ignores unmatched keys\n",
    "print(\"Missing keys:\", missing)\n",
    "print(\"Unexpected keys:\", unexpected)\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "def get_model_size_in_mb(model):\n",
    "    \"\"\"\n",
    "    Get the size (in MB) of a model's parameters and buffers on GPU memory.\n",
    "    \"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_in_bytes = param_size + buffer_size\n",
    "    size_in_megabytes = size_in_bytes / (1024 ** 2)  # bytes to MB\n",
    "    return size_in_megabytes\n",
    "\n",
    "def get_trainable_model_size_in_mb(model):\n",
    "    \"\"\"\n",
    "    Returns the total GPU memory (in MB) used by trainable parameters of a model.\n",
    "    \"\"\"\n",
    "    total_bytes = sum(\n",
    "        p.nelement() * p.element_size()\n",
    "        for p in model.parameters()\n",
    "        if p.requires_grad\n",
    "    )\n",
    "    return total_bytes / (1024 ** 2)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to('cuda')\n",
    "def freeze_mae_encoder_and_decoder(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"patch_embed\") or name.startswith(\"blocks\") or \\\n",
    "           name.startswith(\"norm\") or name in [\"cls_token\", \"pos_embed\"] or \\\n",
    "           name.startswith(\"decoder\") or name == \"mask_token\":\n",
    "            param.requires_grad = False\n",
    "freeze_mae_encoder_and_decoder(model)\n",
    "model_size_mb = get_trainable_model_size_in_mb(model)\n",
    "print(f\"Model size on GPU: {model_size_mb:.2f} MB\")"
   ],
   "id": "cab083bbd964301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sequence_detection.train_mae_finetune import Trainer\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "freeze_mae_encoder = True\n",
    "TRAIN_EPOCHS = 1000\n",
    "cls_strategy = 'cls_token'\n",
    "if freeze_mae_encoder:\n",
    "    path_save = \"./finetune_models/sequence_detection/max_train_len_freeze_mae_encoder_\" + cls_strategy + \"_e\" + str(TRAIN_EPOCHS) + '/'\n",
    "else:\n",
    "    path_save = \"./finetune_models/sequence_detection/max_train_len_nofreeze_mae_encoder_\" + cls_strategy + \"_e\" + str(TRAIN_EPOCHS) + '/'\n",
    "\n",
    "create_path(path_save)\n",
    "trainer = Trainer(\n",
    "    loader_train=dataloader_train,\n",
    "    loader_test=dataloader_val,\n",
    "    my_model=model,\n",
    "    my_loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    RESUME_EPOCH=0,\n",
    "    PATH_MODEL=path_save,\n",
    "    device=device,\n",
    "    cls_strategy = cls_strategy,  # or 'cls_token', 'mean_patch', 'mean_all', 'attn_pool',\n",
    "    freeze_mae_encoder=freeze_mae_encoder,\n",
    "    freeze_mae_encoder_decoder=freeze_mae_encoder, # free encoder and decoder for classification to get actual trainable params printed out\n",
    ")\n",
    "\n",
    "trainer.train(epochs=TRAIN_EPOCHS, show_step=500, show_test=True)\n"
   ],
   "id": "a295425af06bb297",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "39e0787a948c60d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
