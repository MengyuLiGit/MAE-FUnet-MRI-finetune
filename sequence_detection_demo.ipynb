{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T04:23:12.425590Z",
     "start_time": "2025-07-18T04:23:07.452846Z"
    }
   },
   "source": [
    "from sequence_detection.models_mae_finetune import MaskedAutoencoderViTClassify\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "detect_sequence = ['T1_T1flair', 'T2', 'T2flair_flair', 'PD', 'T2star_hemo', 'T2star_swi', 'DTI_DWI']\n",
    "model = MaskedAutoencoderViTClassify(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes=len(detect_sequence) + 1, mode='cls')\n",
    "\n",
    "pretrain_path = './finetune_models/sequence_detection/mae_encoder_cls_token_e1000.pt'\n",
    "\n",
    "missing, unexpected = model.load_state_dict(torch.load(pretrain_path)['model_state_dict'], strict=False)  # strict=False ignores unmatched keys\n",
    "print(\"Missing keys:\", missing)\n",
    "print(\"Unexpected keys:\", unexpected)\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "def get_model_size_in_mb(model):\n",
    "    \"\"\"\n",
    "    Get the size (in MB) of a model's parameters and buffers on GPU memory.\n",
    "    \"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_in_bytes = param_size + buffer_size\n",
    "    size_in_megabytes = size_in_bytes / (1024 ** 2)  # bytes to MB\n",
    "    return size_in_megabytes\n",
    "\n",
    "def get_trainable_model_size_in_mb(model):\n",
    "    \"\"\"\n",
    "    Returns the total GPU memory (in MB) used by trainable parameters of a model.\n",
    "    \"\"\"\n",
    "    total_bytes = sum(\n",
    "        p.nelement() * p.element_size()\n",
    "        for p in model.parameters()\n",
    "        if p.requires_grad\n",
    "    )\n",
    "    return total_bytes / (1024 ** 2)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to('cuda')\n",
    "def freeze_mae_encoder_and_decoder(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"patch_embed\") or name.startswith(\"blocks\") or \\\n",
    "           name.startswith(\"norm\") or name in [\"cls_token\", \"pos_embed\"] or \\\n",
    "           name.startswith(\"decoder\") or name == \"mask_token\":\n",
    "            param.requires_grad = False\n",
    "freeze_mae_encoder_and_decoder(model)\n",
    "model_size_mb = get_trainable_model_size_in_mb(model)\n",
    "print(f\"Model size on GPU: {model_size_mb:.2f} MB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: []\n",
      "111913992\n",
      "111661832\n",
      "Model size on GPU: 0.02 MB\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T04:23:12.542974Z",
     "start_time": "2025-07-18T04:23:12.538875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_sequence(model, image_path, detect_sequence, device='cuda', cls_strategy='cls_token'):\n",
    "    \"\"\"\n",
    "    Predict MRI sequence label from a single slice image.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model with .forward_cls() method\n",
    "        image_path: Path to the input PNG image\n",
    "        device: 'cuda' or 'cpu'\n",
    "        cls_strategy: Classification strategy used in the model\n",
    "\n",
    "    Returns:\n",
    "        (predicted_index, predicted_label)\n",
    "    \"\"\"\n",
    "    import torchvision.transforms as T\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "\n",
    "    # === Load grayscale image\n",
    "    img = Image.open(image_path).convert('L')\n",
    "\n",
    "    # === Convert to numpy and min-max normalize\n",
    "    img_np = np.array(img).astype(np.float32)\n",
    "    if img_np.max() > img_np.min():\n",
    "        img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    else:\n",
    "        img_np[:] = 0.0  # Avoid division by zero\n",
    "\n",
    "    # === Convert to 3-channel\n",
    "    img_3ch = np.stack([img_np] * 3, axis=-1)  # shape: (H, W, 3)\n",
    "\n",
    "    # === Convert to PIL and apply transforms\n",
    "    img_pil = Image.fromarray((img_3ch * 255).astype(np.uint8))\n",
    "    transform = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),  # (3, 224, 224), float32 in [0, 1]\n",
    "    ])\n",
    "    img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    # === Run inference\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model.forward_cls(img_tensor, cls_strategy=cls_strategy)\n",
    "        pred_index = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    pred_label = detect_sequence[pred_index]\n",
    "    return pred_index, pred_label\n"
   ],
   "id": "540bd21104adf374",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T04:23:12.953127Z",
     "start_time": "2025-07-18T04:23:12.553130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = './demo_data/sequence_detection/T2star_swi/2.png'\n",
    "\n",
    "# Predict\n",
    "pred_idx, pred_label = predict_sequence(model, image_path, detect_sequence=detect_sequence, device='cuda')\n",
    "print(f\"Predicted index: {pred_idx}\")\n",
    "print(f\"Predicted label: {pred_label}\")\n"
   ],
   "id": "6f12919e9488ea27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted index: 5\n",
      "Predicted label: T2star_swi\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
