{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from multi_seg.models_mae_finetune_seg import MaskedAutoencoderViTMultiSeg\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "mode = 'mae_unet_fuse'\n",
    "INPUT_SIZE = 224\n",
    "# mode = 'CNN'\n",
    "mae_model = MaskedAutoencoderViTMultiSeg(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12,\n",
    "        decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6), num_classes=2, mode=mode,\n",
    "                 drop=0.1, attn_drop=0.1, drop_path=0.05)\n",
    "\n",
    "pretrain_path = \"./saved_models/mae_vit_base_patch16_pretrain_test0.75_E30/model_E30.pt\"\n",
    "finetuned_path = \"./finetune_models/skull_strip/syn_mae_unet64concat_fuze_skip_7_e1000_1.pt\"\n",
    "\n",
    "missing, unexpected = mae_model.load_state_dict(torch.load(pretrain_path)['model_state_dict'], strict=False)  # strict=False ignores unmatched keys\n",
    "from multi_seg.mae_unet_fuse import UnetWithMAEFusion\n",
    "from modeling.unet import Unet\n",
    "CHANS = 64\n",
    "unet_model = Unet(in_chans=3,out_chans=2, chans=CHANS, if_classify= False,  dim=INPUT_SIZE, mlp_ratio = 32)\n",
    "\n",
    "print(sum(p.numel() for p in unet_model.parameters()))\n",
    "print(sum(p.numel() for p in unet_model.parameters() if p.requires_grad))\n",
    "print(next(unet_model.parameters()).dtype)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = UnetWithMAEFusion(unet=unet_model, mae_model=mae_model, custom_fusion_modes=['concat', 'concat', 'concat', 'concat', 'concat', 'concat', 'concat', 'concat', 'concat'], mae_indices = [0, 2, 5, 8, 11, 8, 5, 2, 0], skip_connect = True, skip_type = 'concat')\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(next(model.parameters()).dtype)\n",
    "missing, unexpected = model.load_state_dict(torch.load(finetuned_path)['model_state_dict'], strict=False)  # strict=False ignores unmatched keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "152ab9bed8a9e6aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "class_colors = [\n",
    "    (0.0, 0.0, 0.0),       # 0: Black (Background)\n",
    "    (0.9, 0.9, 0.0),       # 13: Yellow\n",
    "]\n",
    "# Normalize RGB values if they are in 0â€“255\n",
    "class_colors = [(r, g, b) if max((r, g, b)) <= 1 else (r / 255, g / 255, b / 255)\n",
    "                for (r, g, b) in class_colors]\n",
    "\n",
    "custom_cmap = ListedColormap(class_colors)\n",
    "custom_norm = BoundaryNorm(boundaries=np.arange(15) - 0.5, ncolors=14)\n",
    "def plot_single_png_prediction(\n",
    "    image_png_path, mask_png_path,\n",
    "    models, model_names,\n",
    "    selected_classes=None,\n",
    "    device='cuda',\n",
    "    save_path=None\n",
    "):\n",
    "    assert len(models) == len(model_names), \"Each model must have a name\"\n",
    "\n",
    "    # Load image (grayscale, [H, W])\n",
    "    img = imageio.imread(image_png_path).astype(np.float32) / 255.0\n",
    "    mask = imageio.imread(mask_png_path).astype(np.int64)  # [H, W]\n",
    "\n",
    "    # Prepare input tensor\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0).repeat(3, 1, 1).unsqueeze(0).to(device)  # [1, 3, H, W]\n",
    "\n",
    "    # Load models to device\n",
    "    for i in range(len(models)):\n",
    "        models[i] = models[i].to(device)\n",
    "        models[i].eval()\n",
    "\n",
    "    # Predict\n",
    "    preds_all = []\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            logits = model(img_tensor)  # [1, C, H, W]\n",
    "            pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy()  # [H, W]\n",
    "            preds_all.append(pred)\n",
    "\n",
    "    # Prepare GT\n",
    "    gt_mask = mask\n",
    "    if selected_classes is not None:\n",
    "        gt_mask = np.where(np.isin(gt_mask, selected_classes), gt_mask, 0)\n",
    "    gt_mask_masked = np.ma.masked_where(gt_mask == 0, gt_mask)\n",
    "\n",
    "    # === Plotting: raw + GT + N predictions\n",
    "    num_cols = 2 + len(models)\n",
    "    fig, axs = plt.subplots(1, num_cols, figsize=(4 * num_cols, 5))\n",
    "\n",
    "    # Raw MRI\n",
    "    axs[0].imshow(img, cmap='gray')\n",
    "    axs[0].set_title(\"Raw MRI\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # GT overlay\n",
    "    axs[1].imshow(img, cmap='gray')\n",
    "    axs[1].imshow(gt_mask_masked, cmap=custom_cmap, norm=custom_norm, alpha=0.5)\n",
    "    axs[1].set_title(\"Ground Truth\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Model predictions\n",
    "    for m_idx, (pred_mask, name) in enumerate(zip(preds_all, model_names)):\n",
    "        if selected_classes is not None:\n",
    "            pred_mask = np.where(np.isin(pred_mask, selected_classes), pred_mask, 0)\n",
    "\n",
    "        pred_mask_masked = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
    "\n",
    "        axs[2 + m_idx].imshow(img, cmap='gray')\n",
    "        axs[2 + m_idx].imshow(pred_mask_masked, cmap=custom_cmap, norm=custom_norm, alpha=0.5)\n",
    "        axs[2 + m_idx].set_title(f\"{name} Prediction\")\n",
    "        axs[2 + m_idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=200)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f62404374c22fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plot_single_png_prediction(\n",
    "    image_png_path=\"./demo_data/skull_strip/img1.png\",\n",
    "    mask_png_path=\"./demo_data/skull_strip/mask1.png\",\n",
    "    models=[model],\n",
    "    model_names=[\"MySegModel\"],\n",
    "    device='cuda'\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b6caac18e0c6bb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
