{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-17T23:31:30.764163Z",
     "start_time": "2024-11-17T23:31:23.715243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limengyu\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.nets import SwinUNETR\n",
    "# \n",
    "# # Initialize the model\n",
    "# model = SwinUNETR(\n",
    "#     img_size=(96, 96, 96),  # Input image size\n",
    "#     in_channels=1,          # Number of input channels (e.g., 1 for grayscale MRI)\n",
    "#     out_channels=2,         # Number of output channels (e.g., number of segmentation classes)\n",
    "#     feature_size=48,        # Feature size\n",
    "#     use_checkpoint=True     # Use checkpointing to save memory\n",
    "# )\n",
    "# \n",
    "# # Example input tensor\n",
    "# input_tensor = torch.rand(1, 1, 96, 96, 96)  # Batch size 1, 1 channel, 96x96x96 volume\n",
    "# \n",
    "# # Forward pass\n",
    "# output = model(input_tensor)\n",
    "# print(output.shape)  # Output tensor shape\n",
    "from help_func import print_var_detail"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_3d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    \"\"\"\n",
    "    grid_size: tuple of (grid_d, grid_h, grid_w) representing depth, height, width of the grid\n",
    "    return:\n",
    "    pos_embed: [grid_d*grid_h*grid_w, embed_dim] or [1+grid_d*grid_h*grid_w, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_d = np.arange(grid_size[0], dtype=np.float32)\n",
    "    grid_h = np.arange(grid_size[1], dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size[2], dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h, grid_d, indexing='ij')  # w, h, d indexing\n",
    "    grid = np.stack(grid, axis=0)  # (3, grid_d, grid_h, grid_w)\n",
    "\n",
    "    grid = grid.reshape([3, -1])  # Flatten to (3, grid_d * grid_h * grid_w)\n",
    "    \n",
    "    \n",
    "    \n",
    "    pos_embed = get_3d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    \n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed\n",
    "\n",
    "\n",
    "def get_3d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    \"\"\"\n",
    "    embed_dim: Total embedding dimension\n",
    "    grid: flattened grid of shape (3, grid_d * grid_h * grid_w)\n",
    "    \"\"\"\n",
    "\n",
    "    assert embed_dim % 3 == 0  # Divide embedding equally among depth, height, and width\n",
    "    emb_d = get_1d_sincos_pos_embed_from_grid(embed_dim // 3, grid[0])  # Encode depth\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 3, grid[1])  # Encode height\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 3, grid[2])  # Encode width\n",
    "\n",
    "    emb = np.concatenate([emb_d, emb_h, emb_w], axis=1)  # Combine depth, height, and width embeddings\n",
    "    return emb\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=float)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega  # (D/2,)\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    \n",
    "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
    "    emb_sin = np.sin(out) # (M, D/2)\n",
    "    emb_cos = np.cos(out) # (M, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    return emb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T23:31:30.772352Z",
     "start_time": "2024-11-17T23:31:30.765166Z"
    }
   },
   "id": "7ddad70a42efc4d3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.blocks import PatchEmbed\n",
    "from timm.models.vision_transformer import Block\n",
    "\n",
    "class MaskedAutoencoder3D(nn.Module):\n",
    "    \"\"\"Masked Autoencoder with 3D Vision Transformer backbone.\"\"\"\n",
    "    def __init__(self, vol_size=(128, 128, 128), patch_size=16, in_chans=1,\n",
    "                 embed_dim=1024, depth=24, num_heads=16,\n",
    "                 decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
    "                 mlp_ratio=4., norm_layer=nn.LayerNorm, norm_pix_loss=False):\n",
    "        super().__init__()\n",
    "        self.in_chans = in_chans\n",
    "        self.patch_size = patch_size\n",
    "        self.norm_pix_loss = norm_pix_loss\n",
    "        self.vol_size = vol_size\n",
    "        self.patch_size= patch_size\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # MAE encoder specifics\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            patch_size=(patch_size, patch_size, patch_size),\n",
    "            in_chans=in_chans,\n",
    "            embed_dim=embed_dim,\n",
    "            spatial_dims=3,\n",
    "            norm_layer=norm_layer\n",
    "        )\n",
    "\n",
    "        num_patches = (vol_size[0] // patch_size) * (vol_size[1] // patch_size) * (vol_size[2] // patch_size)\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim), requires_grad=False)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(embed_dim, num_heads, mlp_ratio, qkv_bias=True, qk_scale=None, norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # MAE decoder specifics\n",
    "        self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=True)\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_embed_dim))\n",
    "\n",
    "        self.decoder_pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, decoder_embed_dim), requires_grad=False)\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=True, qk_scale=None, norm_layer=norm_layer)\n",
    "            for i in range(decoder_depth)])\n",
    "        self.decoder_norm = norm_layer(decoder_embed_dim)\n",
    "        self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size ** 3 * in_chans, bias=True)  # decoder to patch\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        grid_size = (\n",
    "        self.vol_size[0] // self.patch_size,  # Number of patches along Depth\n",
    "        self.vol_size[1] // self.patch_size,  # Number of patches along Height\n",
    "        self.vol_size[2] // self.patch_size,  # Number of patches along Width\n",
    "        )\n",
    "        pos_embed = get_3d_sincos_pos_embed(self.pos_embed.shape[-1], grid_size, cls_token=True)\n",
    "        print(pos_embed.shape)\n",
    "        print(self.pos_embed.data.shape)\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "        decoder_pos_embed = get_3d_sincos_pos_embed(self.decoder_pos_embed.shape[-1], grid_size, cls_token=True)\n",
    "        self.decoder_pos_embed.data.copy_(torch.from_numpy(decoder_pos_embed).float().unsqueeze(0))\n",
    "\n",
    "        torch.nn.init.normal_(self.cls_token, std=.02)\n",
    "        torch.nn.init.normal_(self.mask_token, std=.02)\n",
    "\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking.\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "        noise = torch.rand(N, L, device=x.device)\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)\n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).expand(-1, -1, D))\n",
    "\n",
    "        mask = torch.ones([N, L], device=x.device)\n",
    "        mask[:, :len_keep] = 0\n",
    "        mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "        return x_masked, mask, ids_restore\n",
    "\n",
    "    def forward_encoder(self, x, mask_ratio):\n",
    "        print_var_detail(x, 'x0')\n",
    "        x = self.patch_embed(x).flatten(2).transpose(1, 2)  # Flatten and transpose\n",
    "        print_var_detail(x, 'x1')\n",
    "        print_var_detail(self.pos_embed[:, 1:, :], 'self.pos_embed[:, 1:, :]')\n",
    "        x = x + self.pos_embed[:, 1:, :]\n",
    "        x, mask, ids_restore = self.random_masking(x, mask_ratio)\n",
    "        cls_token = self.cls_token + self.pos_embed[:, :1, :]\n",
    "        cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        return x, mask, ids_restore\n",
    "\n",
    "    def forward_decoder(self, x, ids_restore):\n",
    "        x = self.decoder_embed(x)\n",
    "        mask_tokens = self.mask_token.repeat(x.shape[0], ids_restore.shape[1] + 1 - x.shape[1], 1)\n",
    "        x_unmasked = torch.cat([x[:, 1:, :], mask_tokens], dim=1)\n",
    "        x_unmasked = torch.gather(x_unmasked, dim=1, index=ids_restore.unsqueeze(-1).expand(-1, -1, x.shape[2]))\n",
    "        x = torch.cat([x[:, :1, :], x_unmasked], dim=1)\n",
    "        x = x + self.decoder_pos_embed\n",
    "\n",
    "        for blk in self.decoder_blocks:\n",
    "            x = blk(x)\n",
    "        x = self.decoder_norm(x)\n",
    "        x = self.decoder_pred(x)\n",
    "        return x[:, 1:, :]\n",
    "\n",
    "    def forward_loss(self, imgs, pred, mask):\n",
    "        \"\"\"\n",
    "        imgs: (B, C, D, H, W)\n",
    "        pred: (B, num_patches, patch_size^3 * C)\n",
    "        mask: (B, num_patches), 0 is keep, 1 is remove\n",
    "        \"\"\"\n",
    "        target = self.patchify(imgs)  # Convert original images to patch format\n",
    "        if self.norm_pix_loss:\n",
    "            mean = target.mean(dim=-1, keepdim=True)\n",
    "            var = target.var(dim=-1, keepdim=True)\n",
    "            target = (target - mean) / (var + 1.e-6) ** 0.5\n",
    "    \n",
    "        loss = (pred - target) ** 2\n",
    "        loss = loss.mean(dim=-1)  # Mean over patch dimensions\n",
    "        return (loss * mask).sum() / mask.sum()  # Weighted mean over masked patches\n",
    "\n",
    "\n",
    "    def forward(self, imgs, mask_ratio=0.75):\n",
    "        latent, mask, ids_restore = self.forward_encoder(imgs, mask_ratio)\n",
    "        pred = self.forward_decoder(latent, ids_restore)\n",
    "        loss = self.forward_loss(imgs, pred, mask)\n",
    "        return loss, pred, mask\n",
    "    \n",
    "    def patchify(self, imgs):\n",
    "        \"\"\"\n",
    "        Break a 3D volume into non-overlapping patches.\n",
    "        Args:\n",
    "            imgs (torch.Tensor): Input tensor of shape (B, C, D, H, W).\n",
    "        Returns:\n",
    "            torch.Tensor: Flattened patches of shape (B, num_patches, patch_size^3 * C).\n",
    "        \"\"\"\n",
    "        p = self.patch_size  # Patch size (assumed isotropic for simplicity)\n",
    "        assert imgs.shape[2] % p == 0 and imgs.shape[3] % p == 0 and imgs.shape[4] % p == 0, \\\n",
    "            f\"Volume dimensions {imgs.shape[2:]} must be divisible by patch size {p}\"\n",
    "    \n",
    "        # Reshape and permute to create patches\n",
    "        d, h, w = imgs.shape[2] // p, imgs.shape[3] // p, imgs.shape[4] // p\n",
    "        x = imgs.reshape(imgs.shape[0], imgs.shape[1], d, p, h, p, w, p)\n",
    "        x = x.permute(0, 2, 4, 6, 1, 3, 5, 7).contiguous()  # (B, D, H, W, C, p, p, p)\n",
    "        x = x.reshape(imgs.shape[0], d * h * w, p ** 3 * imgs.shape[1])  # Flatten patches\n",
    "        return x\n",
    "\n",
    "    def unpatchify(self, x):\n",
    "        \"\"\"\n",
    "        Reconstruct the 3D volume from flattened patches.\n",
    "        Args:\n",
    "            x (torch.Tensor): Flattened patches of shape (B, num_patches, patch_size^3 * C).\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed volume of shape (B, C, D, H, W).\n",
    "        \"\"\"\n",
    "        p = self.patch_size  # Patch size (assumed isotropic for simplicity)\n",
    "        d = h = w = cubic_root(x.shape[1])  # Number of patches along each dimension\n",
    "        print_var_detail(x,'xx')\n",
    "        print(d)\n",
    "        assert d * h * w == x.shape[1], \"Number of patches does not form a cube\"\n",
    "        \n",
    "        c = x.shape[2] // (p ** 3)  # Derive the number of channels from the flattened patch size\n",
    "        \n",
    "        # Reshape patches back to structured volume\n",
    "        x = x.reshape(x.shape[0], d, h, w, c, p, p, p)  # (B, D, H, W, C, p, p, p)\n",
    "        x = x.permute(0, 4, 1, 5, 2, 6, 3, 7).contiguous()  # Rearrange dimensions to (B, C, D*p, H*p, W*p)\n",
    "        x = x.reshape(x.shape[0], c, d * p, h * p, w * p)  # Merge patch dimensions\n",
    "        return x\n",
    "\n",
    "\n",
    "def cubic_root(n):\n",
    "    \"\"\"\n",
    "    Compute the integer cubic root of a perfect cube.\n",
    "    Args:\n",
    "        n (int): The input number (must be a perfect cube).\n",
    "    Returns:\n",
    "        int: The integer cubic root of n.\n",
    "    \"\"\"\n",
    "    root = round(n ** (1 / 3))  # Compute the approximate cubic root\n",
    "    if root ** 3 != n:  # Verify the result\n",
    "        raise ValueError(f\"The input {n} is not a perfect cube.\")\n",
    "    return root\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T23:31:30.893472Z",
     "start_time": "2024-11-17T23:31:30.772352Z"
    }
   },
   "id": "5ab840967b43f5bb",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cubic_root(1728)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T23:31:30.898848Z",
     "start_time": "2024-11-17T23:31:30.894475Z"
    }
   },
   "id": "95734780bd5df04a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4097, 1536)\n",
      "torch.Size([1, 4097, 1536])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = MaskedAutoencoder3D(vol_size=(256, 256, 256), patch_size=16, in_chans=1, embed_dim=1536, num_heads=16, decoder_embed_dim=768)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T23:31:40.497642Z",
     "start_time": "2024-11-17T23:31:37.199656Z"
    }
   },
   "id": "de05925dcff244b3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is a  <class 'torch.Tensor'> with shape torch.Size([1, 1536, 16, 16, 16]) max:  tensor(4.3773, grad_fn=<MaxBackward1>) min:  tensor(-4.3615, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.rand(1, 1, 256, 256, 256)  # Batch size 2, channels 1, volume 128x128x128\n",
    "asd = model.patch_embed(input_tensor)\n",
    "print_var_detail(asd)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T23:32:16.318854Z",
     "start_time": "2024-11-17T23:32:16.123156Z"
    }
   },
   "id": "72f156d68b1b0d82",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Input 3D MRI volume\n",
    "\n",
    "loss, pred, mask = model(input_tensor, mask_ratio=0.75)\n",
    "\n",
    "# Reconstruct volume\n",
    "reconstructed_volume = model.unpatchify(pred)\n",
    "print(f\"Loss: {loss.item()}, Pred Shape: {pred.shape}, Reconstructed Volume Shape: {reconstructed_volume.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf3ea14c24e12cf3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is a  <class 'torch.Tensor'> with shape torch.Size([1, 4096]) max:  tensor(1.) min:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print_var_detail(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T09:37:32.319026Z",
     "start_time": "2024-11-17T09:37:32.314940Z"
    }
   },
   "id": "74ce497f79c72fb",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xx is a  <class 'torch.Tensor'> with shape torch.Size([1, 4096, 4096]) max:  tensor(1.) min:  tensor(0.)\n",
      "16\n",
      " is a  <class 'torch.Tensor'> with shape torch.Size([1, 1, 256, 256, 256]) max:  tensor(1.) min:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "def reshape_mask(mask, vol_size, patch_size):\n",
    "    \"\"\"\n",
    "    Reshape the mask to match the 3D volume grid.\n",
    "    Args:\n",
    "        mask (torch.Tensor): Mask of shape (B, num_patches).\n",
    "        vol_size (tuple): Original MRI volume size (D, H, W).\n",
    "        patch_size (int): Patch size for each dimension.\n",
    "    Returns:\n",
    "        torch.Tensor: Mask reshaped to 3D grid (B, D, H, W).\n",
    "    \"\"\"\n",
    "    B, num_patches = mask.shape\n",
    "    D, H, W = vol_size[0] // patch_size, vol_size[1] // patch_size, vol_size[2] // patch_size\n",
    "\n",
    "    # Reshape to 3D grid\n",
    "    mask_3d = mask.reshape(B, D, H, W)\n",
    "    return mask_3d\n",
    "# mask_3d = reshape_mask(mask, (256, 256, 256), 16)\n",
    "mask_3d = mask.unsqueeze(-1).repeat(1, 1, model.in_chans * model.patch_size ** 3)\n",
    "mask_3d = model.unpatchify(mask_3d)\n",
    "print_var_detail(mask_3d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T09:37:38.542630Z",
     "start_time": "2024-11-17T09:37:38.465830Z"
    }
   },
   "id": "d75253d7f4891028",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x500 with 18 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_3d_mask(mask_3d, num_slices=6):\n",
    "    \"\"\"\n",
    "    Display slices of a 3D mask using matplotlib.\n",
    "    Args:\n",
    "        mask_3d (torch.Tensor): 3D mask tensor of shape (D, H, W).\n",
    "        num_slices (int): Number of slices to display along the depth dimension.\n",
    "    \"\"\"\n",
    "    mask_3d = mask_3d.squeeze(0).cpu().numpy()  # Remove batch dimension and convert to numpy\n",
    "    D = mask_3d.shape[0]  # Depth of the volume\n",
    "\n",
    "    # Determine slice indices to display\n",
    "    slice_indices = [int(i * D / num_slices) for i in range(num_slices)]\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, num_slices, figsize=(15, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(mask_3d[slice_indices[i]], cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Slice {slice_indices[i]}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Display the 3D mask\n",
    "display_3d_mask(mask_3d[0], num_slices=18)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T09:38:46.818834Z",
     "start_time": "2024-11-17T09:38:46.159849Z"
    }
   },
   "id": "66b385e403990bdd",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerDecoderLayer.forward() missing 1 required positional argument: 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Test input\u001B[39;00m\n\u001B[0;32m      2\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m128\u001B[39m)  \u001B[38;5;66;03m# Batch size 2, channels 1, volume 128x128x128\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m output \u001B[38;5;241m=\u001B[39m model(input_tensor)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutput shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 84\u001B[0m, in \u001B[0;36mMaskedAutoencoder3D.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;124;03mFull forward pass.\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     83\u001B[0m latent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_encoder(x)\n\u001B[1;32m---> 84\u001B[0m reconstruction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_decoder(latent)\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m reconstruction\n",
      "Cell \u001B[1;32mIn[6], line 75\u001B[0m, in \u001B[0;36mMaskedAutoencoder3D.forward_decoder\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     73\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_embed(x)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_blocks:\n\u001B[1;32m---> 75\u001B[0m     x \u001B[38;5;241m=\u001B[39m blk(x)\n\u001B[0;32m     76\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_pred(x)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: TransformerDecoderLayer.forward() missing 1 required positional argument: 'memory'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test input\n",
    "input_tensor = torch.rand(1, 1, 128, 128, 128)  # Batch size 2, channels 1, volume 128x128x128\n",
    "output = model(input_tensor)\n",
    "print(f\"Output shape: {output.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T07:40:15.937375Z",
     "start_time": "2024-11-17T07:40:14.577691Z"
    }
   },
   "id": "9d1cf6d44fefe0aa",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MaskedAutoencoder3D(\n  (encoder_embed): PatchEmbed(\n    (proj): Conv3d(1, 96, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n  )\n  (blocks): ModuleList(\n    (0): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n        )\n        (linear1): Linear(in_features=96, out_features=384, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=384, out_features=96, bias=True)\n        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (1): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n        )\n        (linear1): Linear(in_features=192, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=768, out_features=192, bias=True)\n        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (2): ModuleList(\n      (0-5): 6 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n        )\n        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (3): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (projections): ModuleList(\n    (0): Linear(in_features=96, out_features=192, bias=True)\n    (1): Linear(in_features=192, out_features=384, bias=True)\n    (2): Linear(in_features=384, out_features=768, bias=True)\n  )\n  (encoder_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (decoder_embed): Linear(in_features=768, out_features=512, bias=True)\n  (decoder_blocks): ModuleList(\n    (0-7): 8 x TransformerDecoderLayer(\n      (self_attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n      )\n      (multihead_attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n      )\n      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (dropout3): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (decoder_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  (decoder_pred): Linear(in_features=512, out_features=64, bias=True)\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T07:28:46.712641Z",
     "start_time": "2024-11-17T07:28:46.708389Z"
    }
   },
   "id": "e3ae78aa1a2035a7",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 230.38 MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate model size\n",
    "model_size = sum(p.numel() for p in model.parameters()) * 4 / (1024 ** 2)  # Size in MB\n",
    "print(f\"Model size: {model_size:.2f} MB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T07:28:48.013121Z",
     "start_time": "2024-11-17T07:28:48.009486Z"
    }
   },
   "id": "d705c141aa2b088b",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaskedAutoencoder3D' object has no attribute 'random_masking'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Input: 3D MRI volume (B, C, D, H, W)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m48\u001B[39m, \u001B[38;5;241m48\u001B[39m, \u001B[38;5;241m48\u001B[39m)  \u001B[38;5;66;03m# Batch size 2, 1 channel\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m loss, pred, mask \u001B[38;5;241m=\u001B[39m model(input_tensor, mask_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.75\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Outputs\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Prediction Shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpred\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Mask Shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmask\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[26], line 93\u001B[0m, in \u001B[0;36mMaskedAutoencoder3D.forward\u001B[1;34m(self, imgs, mask_ratio)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, imgs, mask_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.75\u001B[39m):\n\u001B[0;32m     90\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;124;03m    Full forward pass through the MAE.\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 93\u001B[0m     latent, mask, ids_restore \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_encoder(imgs, mask_ratio)\n\u001B[0;32m     94\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_decoder(latent, ids_restore)\n\u001B[0;32m     95\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_loss(imgs, pred, mask)\n",
      "Cell \u001B[1;32mIn[26], line 64\u001B[0m, in \u001B[0;36mMaskedAutoencoder3D.forward_encoder\u001B[1;34m(self, x, mask_ratio)\u001B[0m\n\u001B[0;32m     62\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprojections[i](x)\n\u001B[0;32m     63\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_norm(x)  \u001B[38;5;66;03m# Normalize the final encoding\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m x, mask, ids_restore \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_masking(x, mask_ratio)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, mask, ids_restore\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1688\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1687\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1688\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'MaskedAutoencoder3D' object has no attribute 'random_masking'"
     ]
    }
   ],
   "source": [
    "# Test input\n",
    "input_tensor = torch.rand(2, 1, 128, 128, 128)  # Batch size 2, channels 1\n",
    "loss, pred, mask = model(input_tensor, mask_ratio=0.75)\n",
    "\n",
    "print(f\"Loss: {loss.item()}, Prediction Shape: {pred.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T07:28:50.952798Z",
     "start_time": "2024-11-17T07:28:48.947688Z"
    }
   },
   "id": "340f11f534d14951",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ca20063139b5fe8a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
